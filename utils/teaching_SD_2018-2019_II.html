<!DOCTYPE html>
<html lang="en">
	<head>
			<meta name="author" content="Zoltan Szabo" />
			<meta name="description" content="Zoltán Szabó's Home Page (Department of Statistics, LSE)" />
			<meta name="keywords" content="information theory, kernel methods, statistical machine learning, scalable computation,
			randomized algorithms, shape-constrained prediction, hypothesis testing, safety-critical learning, style transfer,
			distribution regression, dictionary learning, structured sparsity, independent subspace analysis, bioinformatics,
			Bayesian inference, computer vision, finance, economics, analysis of climate data, criminal data analysis, collaborative filtering,
			emotion recognition, face tracking, remote sensing, natural language processing, gene analysis" />
			<meta charset="UTF-8">
	   	<title> Zoltán Szabó's Home Page </title>
   	   <style>
   	    		@import url("css/style.css");
    		</style>
	</head>
	<body>
			   <div class="center menu">
	  	 			<nav>
   	    			<a href="../index.html">Home</a> -
  	   	 			<a href="../publications.html">Publications</a> -
     	 				<a href="../service.html">Service</a> -
     	 				<a href="../talks.html">Talks</a> -
							<a href="../software.html">Software</a> -
              <a href="../teaching.html">Teaching</a>
   				</nav>
  				</div>

			  	<div class="left">
					<p class="name"> <b>Teaching</b>: 2019, Spring (Master 2 Data Science course @ University of Paris-Saclay).
		      </div>

					<div class="center">
						 <img src="img/graph4.png" height = "150" alt="graph">
						 <br>
				 </div>

				<div class="left">
					Structured Data: Learning, Prediction, Dependency, Testing:
					<ul>
						 <li>Goal:
							 <ul>
								 			<li> Many real-world applications involve objects with an explicit or implicit structure. Social networks, protein-protein interaction networks, molecules, DNA sequences and syntactic tags are
								        	instances of explicitly structured data while texts, images, videos, biomedical signals are examples with implicit structure. The focus of the course is solving learning and prediction tasks,
								        	estimation of dependency measures, and hypothesis testing under this complex/structured assumption. </li>

								      <li>  While in learning and prediction problems the case of structured inputs has been investigated for about three decades, structural assumption on the output side is a significantly
								        more challenging and less understood area of statistical learning. The first part of the course provides a transversal and comprehensive overview on the recent advances and
								        tools for this exploding field of structured output learning, including graphical models, max margin approaches as well as deep learning. The covered methods are mainly
								        energy-based techniques among which  (1) max margin approaches, conditional random fields, deep structured learning, and (2) structured output regression algorithms.
								        These approaches illustrated on real applications will allow to cope with complex problems such as question-answering, automatic captioning, molecule identification.
								        Finally both families of methods (1) and (2) will be studied under the angle of generalization and consistency. </li>

								      <li>  The second part of the course gives an alternative view on the structured problem family, dealing with topics on <em>dependency estimation and hypothesis testing</em>.
								        Emerging methods in these fields can not only lead to state-of-the-art algorithms in several application areas (such as blind signal separation, feature selection,
								        outlier-robust image registration, regression problems on probability distributions), but they also come with elegant performance guarantees, complementing
								        the regular statistical tools restricted to unstructured Euclidean domains. We are going to construct features of probability distributions which will enable us
								        to define easy-to-estimate independence measures and distances of random variables. As a byproduct, we will get nonparametric extensions of the classical
								        t-test (two-sample test) and the Pearson correlation test (independence test). </li>

							 </ul>
						 </li>

						 <li>Lecturers: <a href="https://perso.telecom-paristech.fr/fdalche/">Florence d'Alché-Buc</a>, Zoltán Szabó,
							     <a href="http://perso.telecom-paristech.fr/~essid/">Slim Essid</a>.
						 </li>

						 	<li> Place: Télécom ParisTech (1st part), École Polytechnique (2nd = my part).
							</li>

						  <li>Prerequisites:
									<ul>
										<li> The course requires a basic knowledge of kernel methods, graphical models, deep learning, optimization and functional analysis. </li>
									</ul>
							</li>

							<li>Exam:
									<ul>
											<li> 2 Projects. </li>
											<li> Topics: link prediction, question answering, image/document understanding, drug activity prediction, molecule prediction, functional prediction, information theoretical optimization (including two-sample and independence testing). </li>
									</ul>
							</li>
						</ul>

							<hr>
						  <ul>

							<li>2nd part (Zoltán, Feb. 25-):
  					    		<ul>
												<li> Keywords:
														<ul>
																<li> Kernel canonical correlation analysis, mean embedding, maximum mean discrepancy, integral probability metric, characteristic/universal kernel, Hilbert-Schmidt independence criterion, covariance operator, Hilbert-Schmidt norm. </li>
																<li> Kernel based two-sample and independence tests. Quadratic and linear-time methods. </li>
														</ul>
												</li>
												<li> Slides:
														<ul>
																	<li>Feb. 25, Mar. 4, 18, 25:  <a href="../teaching/X/SD/2018-2019_II/lecture_1-4.pdf">main</a>, <a href="../teaching/X/SD/2018-2019_II/lecture_1_supplement.pdf">supplement (kernel, RKHS)</a>. </li>
														</ul>
												</li>
												<li> Code:
														<ul>
														 		<li> Information Theoretical Estimators (ITE) toolbox in <a href="https://bitbucket.org/szzoli/ite-in-python/">Python</a>, <a href="https://bitbucket.org/szzoli/ite/">Matlab</a>.  </li>
														 		<li> <a href="https://github.com/wittawatj/interpretable-test">Two-sample test</a>, <a href="https://github.com/wittawatj/fsic-test">independence test</a>, <a href="https://github.com/wittawatj/kernel-gof">goodness-of-fit test</a>.
														</ul>
												</li>
                 		</ul>
              </li>


            	</ul>
  				</div>

	</body>
</html>
